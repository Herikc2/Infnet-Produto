{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importando bibliotecas que serão úteis para o classificador XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, Conv1D, Flatten, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "import pickle\n",
    "\n",
    "# Scipy\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Carregando a base de dados a ser utilizada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('datasets/df_sem_duplicatas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set-Up do LabelEncoder model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['categoria'])\n",
    "df['Categoria'] = le.transform(df['categoria'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Divisao da base em teste e de treinamento e vetorização utilizando TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature-target split\n",
    "X, y = df.drop('Categoria', axis = 1), df['Categoria']\n",
    "\n",
    "# Train-test split (from complete data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 40)\n",
    "data_train = pd.concat([X_train, y_train], axis = 1)\n",
    "\n",
    "# Validation-test split (from test data)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 40) \n",
    "data_val, data_test = pd.concat([X_val, y_val], axis = 1), pd.concat([X_test, y_test], axis = 1)\n",
    "\n",
    "# Comparison of sizes of training set, validation set and test set\n",
    "values = np.array([len(data_train), len(data_val), len(data_test)])\n",
    "labels = ['Training set', 'Validation Set', 'Test set']\n",
    "fig = go.Figure(data = [go.Pie(values = values, labels = labels, hole = 0.5, textinfo = 'percent', title = \" \")])\n",
    "text_title = \"Comparison of sizes of training set, validation set and test set\"\n",
    "fig.update_layout(height = 500, width = 800, showlegend = True, title = dict(text = text_title, x = 0.5, y = 0.95))\n",
    "fig.show()\n",
    "\n",
    "# TF-IDF vectorization\n",
    "TfidfVec = TfidfVectorizer(ngram_range = (1, 1))\n",
    "X_train_tfidf = TfidfVec.fit_transform(X_train['descricao'].tolist())\n",
    "X_val_tfidf = TfidfVec.transform(X_val['descricao'].tolist())\n",
    "\n",
    "X_test_tfidf = TfidfVec.transform(X_test['descricao'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo Inicial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para geração de matriz de confusao\n",
    "def confusio_matrix(y_test, y_predicted):\n",
    "  y_test_original = le.inverse_transform(y_test)\n",
    "  y_pred_original = le.inverse_transform(pred)\n",
    "  conf_matrix = confusion_matrix(y_test_original,y_pred_original)\n",
    "  labels = np.unique(y_pred_original)\n",
    "  plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "  plt.title('Matriz de Confusão')\n",
    "  plt.colorbar()\n",
    "  tick_marks = np.arange(len(labels))\n",
    "  plt.xticks(tick_marks, labels)\n",
    "  plt.yticks(tick_marks, labels)\n",
    "\n",
    "  for i in range(len(labels)):\n",
    "      for j in range(len(labels)):\n",
    "          plt.text(j, i, str(conf_matrix[i, j]), horizontalalignment='center', verticalalignment='center')\n",
    "  plt.ylabel('Rótulo Verdadeiro')\n",
    "  plt.xlabel('Rótulo Predito')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identação do XGBClassifier na variável modelo\n",
    "modelo = XGBClassifier(objective='binary:logistic', nthread=4, seed=42)\n",
    "\n",
    "#Parâmetros para o GridSearchCV\n",
    "params = {\n",
    "    'max_depth': range (2, 10, 1),\n",
    "    'n_estimators': range(60, 220, 40),\n",
    "    'learning_rate': [0.1, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "#Chamada do GridSearchCV\n",
    "grid = GridSearchCV(modelo, params, n_jobs = -1, cv = 5, scoring = None)\n",
    "\n",
    "#Essa parte do código é para rodar o GridSearchCV e salvar o modelo\n",
    "grid.fit(X_train_tfidf, y_train)\n",
    "pred = grid.predict(X_test_tfidf)\n",
    "modelo_ = grid.best_estimator_\n",
    "\n",
    "#Essa parte printa os best_parmams, ou seja, os melhores parâmetros para o modelo\n",
    "print(grid.best_params_)\n",
    "resultados_df = pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essa parte printa o best_score, ou seja, a melhor acurácia do modelo\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chamada da função que gera a matriz de confusao com os parametros de teste e predição\n",
    "confusio_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo 2 XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parâmetros para o GridSearchCV\n",
    "params = {\n",
    "    'max_depth': [8],\n",
    "    'n_estimators': [180],\n",
    "    'learning_rate': [0.1],\n",
    "    'min_child_weight': range(0, 10),\n",
    "    'reg_lambda': range(1, 2),\n",
    "}\n",
    "\n",
    "#Chamada do GridSearchCV\n",
    "grid = GridSearchCV(modelo, params, n_jobs = -1, cv = 5, scoring = None)\n",
    "\n",
    "#Essa parte do código é para rodar o GridSearchCV e salvar o modelo\n",
    "grid.fit(X_train_tfidf, y_train)\n",
    "pred = grid.predict(X_test_tfidf)\n",
    "modelo_ = grid.best_estimator_\n",
    "\n",
    "#Essa parte printa os best_parmams, ou seja, os melhores parâmetros para o modelo\n",
    "print(grid.best_params_)\n",
    "resultados_df = pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essa parte printa o best_score, ou seja, a melhor acurácia do modelo\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chamada da função que gera a matriz de confusao com os parametros de teste e predição\n",
    "confusio_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo 3 XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parâmetros para o GridSearchCV\n",
    "params = {\n",
    "    'max_depth': [8],\n",
    "    'n_estimators': [180],\n",
    "    'learning_rate': [0.1],\n",
    "    'min_child_weight': range(0, 10),\n",
    "    'reg_lambda': range(1, 2),\n",
    "}\n",
    "\n",
    "#Chamada do GridSearchCV\n",
    "grid = GridSearchCV(modelo, params, n_jobs = 10, cv = 10, scoring = None)\n",
    "\n",
    "#Essa parte do código é para rodar o GridSearchCV e salvar o modelo\n",
    "grid.fit(X_train_tfidf, y_train)\n",
    "pred = grid.predict(X_test_tfidf)\n",
    "modelo_ = grid.best_estimator_\n",
    "\n",
    "#Essa parte printa os best_parmams, ou seja, os melhores parâmetros para o modelo\n",
    "print(grid.best_params_)\n",
    "resultados_df = pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essa parte printa o best_score, ou seja, a melhor acurácia do modelo\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chamada da função que gera a matriz de confusao com os parametros de teste e predição\n",
    "confusio_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando modelo como pickle\n",
    "with open('models/xgboost.pkl', 'wb') as model_file:\n",
    "    pickle.dump(modelo_, model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Teste do Modelo com os melhores parâmetros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametros para o xgboost\n",
    "params_xgb = {\n",
    "    'learning_rate': [0.03, 0.3],\n",
    "    'min_child_weight': [0, 10],\n",
    "    'n_estimators': [200],\n",
    "    'reg_lambda': [1, 2],\n",
    "    'seed': [40]\n",
    "}\n",
    "\n",
    "#Essa parte do codigo serve para rodar o xgboost com os parametros acima\n",
    "xgb = XGBClassifier()\n",
    "best_model_xgb, best_params_xgb, best_score_xgb, count = xgb, ParameterGrid(params_xgb)[0], 0, 0\n",
    "for g in ParameterGrid(params_xgb):\n",
    "    time_start = time.time()\n",
    "    count += 1\n",
    "    xgb.set_params(**g)\n",
    "    xgb.fit(X_train_tfidf, y_train)\n",
    "    y_train_pred, y_val_pred = xgb.predict(X_train_tfidf), xgb.predict(X_val_tfidf)\n",
    "    score_train, score_val = accuracy_score(y_train, y_train_pred), accuracy_score(y_val, y_val_pred)\n",
    "    time_stop = time.time()\n",
    "    m, s = int(time_stop - time_start) // 60, int(time_stop - time_start) % 60\n",
    "    if score_val > best_score_xgb:\n",
    "        best_params_xgb, best_score_xgb = g, score_val\n",
    "best_model_x, best_params_x, best_score_x = XGBClassifier(), best_params_xgb, best_score_xgb\n",
    "best_model_x.set_params(**best_params_x)\n",
    "print(f\"Best model: {best_model_x}\")\n",
    "print(\" \")\n",
    "print(f\"Best parameters: {best_params_x}\")\n",
    "print(f\"Best validation accuracy: {best_score_x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar matriz de confusão com os parâmetros de teste e predição\n",
    "def conf_mat(y_test, y_test_pred, figsize = (10, 8), font_scale = 1.2, annot_kws_size = 16):\n",
    "    class_names = [0, 1, 2, 3] # ['Electronics', 'Household', 'Books', 'Clothing & Accessories']\n",
    "    tick_marks_y = [0.5, 1.5, 2.5, 3.5]\n",
    "    tick_marks_x = [0.5, 1.5, 2.5, 3.5]\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "    confusion_matrix_df = pd.DataFrame(confusion_matrix, range(4), range(4))\n",
    "    plt.figure(figsize = figsize)\n",
    "    sns.set(font_scale = font_scale) # label size\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    sns.heatmap(confusion_matrix_df, annot = True, annot_kws = {\"size\": annot_kws_size}, fmt = 'd') # font size\n",
    "    plt.yticks(tick_marks_y, class_names, rotation = 'vertical')\n",
    "    plt.xticks(tick_marks_x, class_names, rotation = 'horizontal')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Atribuição das variaveis para o modelo\n",
    "best_model, X_train_vec, X_test_vec = best_model_x, X_train_tfidf, X_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Previsão, acurácia e matriz de confusão do modelo utilizando os dados de teste\n",
    "best_model.fit(X_train_vec, y_train)\n",
    "y_test_pred = best_model.predict(X_test_vec)\n",
    "score_test = accuracy_score(y_test, y_test_pred)\n",
    "print(pd.Series({\"Test accuracy\": score_test}).to_string())\n",
    "print(\" \")\n",
    "conf_mat(y_test, y_test_pred, figsize = (10, 8), font_scale = 1.2, annot_kws_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matriz de confusão utilizando os melhores parametros\n",
    "y_test_original = le.inverse_transform(y_test) #\n",
    "y_pred_original = le.inverse_transform(pred)\n",
    "conf_matrix = confusion_matrix(y_test_original,y_pred_original)\n",
    "labels = np.unique(y_pred_original)\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(labels))\n",
    "plt.xticks(tick_marks, labels)\n",
    "plt.yticks(tick_marks, labels)\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    for j in range(len(labels)):\n",
    "        plt.text(j, i, str(conf_matrix[i, j]), horizontalalignment='center', verticalalignment='center')\n",
    "plt.ylabel('Rótulo Verdadeiro')\n",
    "plt.xlabel('Rótulo Predito')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
